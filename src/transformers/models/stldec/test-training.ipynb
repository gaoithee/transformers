{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd3821f0-2dce-4bae-b157-5ab9dbdbfe89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoConfig, AutoModel\n",
    "from configuration import STLConfig\n",
    "from modeling_stldec import STLDec\n",
    "from handcoded_tokenizer import STLTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9fcf934f-4204-4d5a-a94d-bac6bb2688a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "AutoConfig.register(\"stl-dec\", STLConfig)\n",
    "AutoModel.register(STLConfig, STLDec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "faf691d7-ba2b-4424-a107-34bde66a272f",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = STLConfig()\n",
    "model = AutoModel.from_config(config)\n",
    "tokenizer = STLTokenizer('tokenizer_files/tokenizer.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "623703ff-e08e-4d83-a3d8-5ef13f3e2e01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded sequence:  [2, 1, 4, 1, 11, 1, 4, 1, 17, 18, 26, 1, 13, 1, 25, 24, 27, 34, 33, 33, 1, 5, 1, 8, 19, 26, 26, 21, 27, 26, 20, 1, 17, 18, 25, 1, 13, 1, 23, 25, 24, 32, 34, 29, 26, 1, 5, 1, 3]\n"
     ]
    }
   ],
   "source": [
    "sequence = \"( not ( x_1 <= 0.2988 ) until[11,21] x_0 <= -0.7941 )\"\n",
    "tokenizer = STLTokenizer('tokenizer_files/tokenizer.json')\n",
    "token_ids = tokenizer.encode(sequence)\n",
    "# decoded_sequence = tokenizer.decode(token_ids)\n",
    "\n",
    "# print(\"Original sequence: \", sequence)\n",
    "print(\"Encoded sequence: \", token_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70ed1d23-1008-4ab7-bfbb-eaebf77c255a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import json\n",
    "import logging\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "from itertools import chain\n",
    "from pathlib import Path\n",
    "\n",
    "import datasets\n",
    "import torch\n",
    "from accelerate import Accelerator, DistributedType\n",
    "from accelerate.logging import get_logger\n",
    "from accelerate.utils import set_seed\n",
    "from datasets import load_dataset\n",
    "from huggingface_hub import HfApi\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import transformers\n",
    "from transformers import (\n",
    "    CONFIG_MAPPING,\n",
    "    MODEL_MAPPING,\n",
    "    AutoConfig,\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    SchedulerType,\n",
    "    default_data_collator,\n",
    "    get_scheduler,\n",
    ")\n",
    "from transformers.utils import check_min_version, send_example_telemetry\n",
    "from transformers.utils.versions import require_version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85ed27ab-3eb9-4ea5-9bda-4f99b07e5d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import logging\n",
    "import random\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoConfig, AutoTokenizer, AutoModelForCausalLM\n",
    "from transformers import get_scheduler\n",
    "from accelerate import Accelerator\n",
    "from tqdm.notebook import tqdm\n",
    "from itertools import chain\n",
    "from datasets.utils.logging import set_verbosity_warning, set_verbosity_info\n",
    "\n",
    "# Initialize logging\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\",\n",
    "    datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "    level=logging.INFO,\n",
    ")\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73ef70ed-ad81-44f4-a910-3fab9ccf1140",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example configuration variables for Jupyter notebook\n",
    "args = {\n",
    "    'dataset_name': None,  # or a custom dataset path\n",
    "    'train_file': 'formulas_with_embeddings.csv',\n",
    "    'validation_file': None,\n",
    "    'output_dir': './output',\n",
    "    'model_name_or_path': 'stl-dec',\n",
    "    'tokenizer_name': 'stl-dec',\n",
    "    'block_size': 128,\n",
    "    'batch_size': 8,\n",
    "    'gradient_accumulation_steps': 1,\n",
    "    'num_train_epochs': 3,\n",
    "    'learning_rate': 5e-5,\n",
    "    'weight_decay': 0.01,\n",
    "    'num_warmup_steps': 0,\n",
    "    'max_train_steps': None,\n",
    "    'seed': 42,\n",
    "    'with_tracking': False,\n",
    "    'hub_model_id': 'stl-dec',\n",
    "    'push_to_hub': True,\n",
    "    'trust_remote_code': True,\n",
    "    'overwrite_cache': False,\n",
    "    'per_device_train_batch_size': 8,\n",
    "    'per_device_eval_batch_size': 8,\n",
    "    'checkpointing_steps': 'epoch',  # or 'steps' with an int value\n",
    "    'resume_from_checkpoint': None,\n",
    "    'hub_token': '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',\n",
    "}\n",
    "\n",
    "# Initialize the accelerator\n",
    "accelerator = Accelerator()\n",
    "\n",
    "# Send telemetry for resource tracking (assuming you have this function)\n",
    "# send_example_telemetry(\"run_clm_no_trainer\", args)\n",
    "\n",
    "# Set seed\n",
    "if args['seed'] is not None:\n",
    "    torch.manual_seed(args['seed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3391c0e-5120-4b92-b12e-4352a22aa386",
   "metadata": {},
   "outputs": [],
   "source": [
    "if args['push_to_hub']:\n",
    "    print(\"yes\")\n",
    "else:\n",
    "    print(\"no\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0bbeab0b-7c1f-42e4-b6ec-f75dc1be74d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle the repository creation\n",
    "if accelerator.is_main_process:\n",
    "    if args['push_to_hub']:\n",
    "        # Retrieve of infer repo_name\n",
    "        repo_name = args[\"hub_model_id\"]\n",
    "        if repo_name is None:\n",
    "            repo_name = Path(args[\"output_dir\"]).absolute().name\n",
    "        # Create repo and retrieve repo_id\n",
    "        api = HfApi()\n",
    "        repo_id = api.create_repo(repo_name, exist_ok=True, token=args[\"hub_token\"]).repo_id\n",
    "\n",
    "        with open(os.path.join(args[\"output_dir\"], \".gitignore\"), \"w+\") as gitignore:\n",
    "            if \"step_*\" not in gitignore:\n",
    "                gitignore.write(\"step_*\\n\")\n",
    "            if \"epoch_*\" not in gitignore:\n",
    "                gitignore.write(\"epoch_*\\n\")\n",
    "    elif args[\"output_dir\"] is not None:\n",
    "        os.makedirs(args[\"output_dir\"], exist_ok=True)\n",
    "accelerator.wait_for_everyone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c88a275-9b6c-4536-8b7f-d370a5812b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_files = {}\n",
    "data_args = {}\n",
    "\n",
    "if args[\"train_file\"] is not None:\n",
    "    data_files[\"train\"] = args[\"train_file\"]\n",
    "    file_extension = args[\"train_file\"].split(\".\")[-1]\n",
    "if args[\"validation_file\"] is not None:\n",
    "    data_files[\"validation\"] = args[\"validation_file\"]\n",
    "    file_extension = args[\"validation_file\"].split(\".\")[-1]\n",
    "raw_datasets = load_dataset(file_extension, data_files=data_files, **data_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cee18fa3-9d0c-4e18-b524-fa27edc0a026",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Formula', 'Embedding'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8728ba6d-e76f-4b14-8f73-f267610333db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer.encode(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "14094912-9970-4225-a586-1497aa474dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# everything is put together\n",
    "# since we have encoded also BOS (2) and EOS (3) tokens, \n",
    "# it does not matter how long this string is\n",
    "tokenized_datasets = tokenize_function(raw_datasets['train']['Formula'][:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "fca02890-bf06-416a-ac8e-cffd8cac7ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_list(input_list, block_size, padding_token=1):\n",
    "    # Crea una lista di blocchi segmentati con padding se necessario\n",
    "    # Segmenta la lista in blocchi\n",
    "    segmented = [input_list[i:i + block_size] for i in range(0, len(input_list), block_size)]\n",
    "    \n",
    "    # Aggiungi padding all'ultimo blocco se necessario\n",
    "    if len(segmented[-1]) < block_size:\n",
    "        segmented[-1] = segmented[-1] + [padding_token] * (block_size - len(segmented[-1]))\n",
    "    \n",
    "    return segmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "eb50069f-4a94-46bc-93dd-a82e957acb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se il parametro block_size non è stato specificato (cioè args.block_size è None), \n",
    "# il codice imposta block_size al valore massimo di lunghezza del modello (tokenizer.model_max_length)\n",
    "\n",
    "if args[\"block_size\"] is None:\n",
    "    block_size = tokenizer.model_max_length\n",
    "    if block_size > config.max_position_embeddings:\n",
    "            logger.warning(\n",
    "                f\"The tokenizer picked seems to have a very large `model_max_length` ({tokenizer.model_max_length}). \"\n",
    "                f\"Using block_size={min(1024, config.max_position_embeddings)} instead. You can change that default value by passing --block_size xxx.\"\n",
    "            )\n",
    "            block_size = min(1024, config.max_position_embeddings)\n",
    "else:\n",
    "    if args[\"block_size\"] > tokenizer.model_max_length:\n",
    "            logger.warning(\n",
    "                f\"The block_size passed ({args.block_size}) is larger than the maximum length for the model \"\n",
    "                f\"({tokenizer.model_max_length}). Using block_size={tokenizer.model_max_length}.\"\n",
    "            )\n",
    "    block_size = min(args[\"block_size\"], tokenizer.model_max_length)\n",
    "\n",
    "block_size = args['block_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2710fe9d-b409-4830-9ade-bb35c37b26cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(segment_list(tokenized_datasets, block_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ec3d7349-e415-4096-a7e3-54d3270cda21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "268"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenized_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "eb4e8ce3-ca3c-48e9-9eca-0580040874a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# segment_list(tokenized_datasets, block_size)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5b0b692c-ad8b-4fe8-b9ee-6d4f7a43a94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_datasets = segment_list(tokenized_datasets, block_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "978eeae7-0a29-4aa4-8a72-6e0c50d11376",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = lm_datasets\n",
    "\n",
    "# DataLoader creation\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=args['per_device_train_batch_size'], shuffle=True)\n",
    "\n",
    "# Optimizer setup\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=args['learning_rate'], weight_decay=args['weight_decay'])\n",
    "\n",
    "# Scheduler setup\n",
    "num_update_steps_per_epoch = math.ceil(len(train_dataloader) / args['gradient_accumulation_steps'])\n",
    "if args['max_train_steps'] is None:\n",
    "    args['max_train_steps'] = args['num_train_epochs'] * num_update_steps_per_epoch\n",
    "\n",
    "lr_scheduler = get_scheduler(\n",
    "    name='linear', optimizer=optimizer, num_warmup_steps=args['num_warmup_steps'],\n",
    "    num_training_steps=args['max_train_steps']\n",
    ")\n",
    "\n",
    "# Prepare everything with accelerator\n",
    "model, optimizer, train_dataloader, lr_scheduler = accelerator.prepare(\n",
    "    model, optimizer, train_dataloader, lr_scheduler\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "708bc48f-1046-4ccd-a29e-8187bcbce27d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e606c1e5d63410f8d188a2efe3184d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([26,  1,  2], device='cuda:0'), tensor([20,  5,  1], device='cuda:0'), tensor([ 1,  1, 19], device='cuda:0'), tensor([17,  5,  0], device='cuda:0'), tensor([18,  1,  4], device='cuda:0'), tensor([27,  5,  1], device='cuda:0'), tensor([1, 1, 4], device='cuda:0'), tensor([13,  5,  1], device='cuda:0'), tensor([ 1,  0, 17], device='cuda:0'), tensor([25, 20, 18], device='cuda:0'), tensor([24,  1, 26], device='cuda:0'), tensor([30,  3,  1], device='cuda:0'), tensor([30,  1, 13], device='cuda:0'), tensor([30,  1,  1], device='cuda:0'), tensor([29,  1, 25], device='cuda:0'), tensor([ 1,  1, 24], device='cuda:0'), tensor([ 5,  1, 25], device='cuda:0'), tensor([ 1,  1, 30], device='cuda:0'), tensor([ 5,  1, 30], device='cuda:0'), tensor([ 1,  1, 32], device='cuda:0'), tensor([10,  1,  1], device='cuda:0'), tensor([ 1,  1, 10], device='cuda:0'), tensor([4, 1, 1], device='cuda:0'), tensor([ 1,  1, 17], device='cuda:0'), tensor([ 7,  1, 18], device='cuda:0'), tensor([19,  1, 26], device='cuda:0'), tensor([26,  1,  1], device='cuda:0'), tensor([33,  1, 12], device='cuda:0'), tensor([21,  1,  1], device='cuda:0'), tensor([27,  1, 26], device='cuda:0'), tensor([25,  1, 24], device='cuda:0'), tensor([20,  1, 28], device='cuda:0'), tensor([ 1,  1, 32], device='cuda:0'), tensor([ 4,  1, 33], device='cuda:0'), tensor([ 1,  1, 33], device='cuda:0'), tensor([4, 1, 1], device='cuda:0'), tensor([1, 1, 5], device='cuda:0'), tensor([6, 1, 1], device='cuda:0'), tensor([19,  1,  9], device='cuda:0'), tensor([30,  1,  1], device='cuda:0'), tensor([21,  1, 17], device='cuda:0'), tensor([34,  1, 18], device='cuda:0'), tensor([20,  1, 25], device='cuda:0'), tensor([1, 1, 1], device='cuda:0'), tensor([ 4,  1, 13], device='cuda:0'), tensor([1, 1, 1], device='cuda:0'), tensor([17,  1, 25], device='cuda:0'), tensor([18,  1, 24], device='cuda:0'), tensor([25,  1, 33], device='cuda:0'), tensor([ 1,  1, 30], device='cuda:0'), tensor([13,  1, 26], device='cuda:0'), tensor([ 1,  1, 27], device='cuda:0'), tensor([23,  1,  1], device='cuda:0'), tensor([25,  1,  5], device='cuda:0'), tensor([24,  1,  0], device='cuda:0'), tensor([31,  1, 21], device='cuda:0'), tensor([31,  1,  1], device='cuda:0'), tensor([1, 1, 0], device='cuda:0'), tensor([5, 1, 4], device='cuda:0'), tensor([1, 1, 1], device='cuda:0'), tensor([10,  1,  4], device='cuda:0'), tensor([1, 1, 1], device='cuda:0'), tensor([17,  1,  7], device='cuda:0'), tensor([18,  1, 19], device='cuda:0'), tensor([25,  1, 30], device='cuda:0'), tensor([ 1,  1, 21], device='cuda:0'), tensor([13,  1, 34], device='cuda:0'), tensor([ 1,  1, 20], device='cuda:0'), tensor([25,  1,  1], device='cuda:0'), tensor([24,  1,  4], device='cuda:0'), tensor([33,  1,  1], device='cuda:0'), tensor([30,  1,  7], device='cuda:0'), tensor([27,  1,  1], device='cuda:0'), tensor([30,  1,  4], device='cuda:0'), tensor([1, 1, 1], device='cuda:0'), tensor([ 5,  1, 17], device='cuda:0'), tensor([ 1,  1, 18], device='cuda:0'), tensor([ 5,  1, 25], device='cuda:0'), tensor([1, 1, 1], device='cuda:0'), tensor([ 9,  1, 13], device='cuda:0'), tensor([1, 1, 1], device='cuda:0'), tensor([ 7,  1, 23], device='cuda:0'), tensor([19,  1, 25], device='cuda:0'), tensor([26,  1, 24], device='cuda:0'), tensor([32,  1, 31], device='cuda:0'), tensor([21,  1, 29], device='cuda:0'), tensor([22,  1, 33], device='cuda:0'), tensor([20,  1, 31], device='cuda:0'), tensor([1, 1, 1], device='cuda:0'), tensor([4, 1, 5], device='cuda:0'), tensor([1, 1, 1], device='cuda:0'), tensor([4, 1, 5], device='cuda:0'), tensor([1, 1, 1], device='cuda:0'), tensor([6, 1, 9], device='cuda:0'), tensor([1, 1, 1], device='cuda:0'), tensor([4, 1, 4], device='cuda:0'), tensor([1, 1, 1], device='cuda:0'), tensor([17,  1,  6], device='cuda:0'), tensor([18,  1, 19], device='cuda:0'), tensor([25,  1, 26], device='cuda:0'), tensor([ 1,  1, 21], device='cuda:0'), tensor([13,  1, 26], device='cuda:0'), tensor([ 1,  1, 27], device='cuda:0'), tensor([23,  1, 20], device='cuda:0'), tensor([25,  1,  1], device='cuda:0'), tensor([24,  1,  4], device='cuda:0'), tensor([34,  1,  1], device='cuda:0'), tensor([30,  1, 17], device='cuda:0'), tensor([33,  1, 18], device='cuda:0'), tensor([33,  1, 26], device='cuda:0'), tensor([1, 1, 1], device='cuda:0'), tensor([ 5,  1, 12], device='cuda:0'), tensor([1, 1, 1], device='cuda:0'), tensor([10,  1, 25], device='cuda:0'), tensor([ 1,  1, 24], device='cuda:0'), tensor([17,  1, 31], device='cuda:0'), tensor([18,  1, 34], device='cuda:0'), tensor([26,  1, 29], device='cuda:0'), tensor([ 1,  1, 31], device='cuda:0'), tensor([12,  1,  1], device='cuda:0'), tensor([1, 1, 5], device='cuda:0'), tensor([23,  1,  1], device='cuda:0'), tensor([25,  1,  8], device='cuda:0'), tensor([24,  1, 19], device='cuda:0'), tensor([32,  1, 26], device='cuda:0'), tensor([30,  1, 32], device='cuda:0'), tensor([33,  1, 21], device='cuda:0'), tensor([31,  1, 27], device='cuda:0')]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "807b206bb49a4a4190cf51116b0dd8f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([ 1,  2, 26], device='cuda:0'), tensor([ 5,  1, 20], device='cuda:0'), tensor([ 1, 19,  1], device='cuda:0'), tensor([ 5,  0, 17], device='cuda:0'), tensor([ 1,  4, 18], device='cuda:0'), tensor([ 5,  1, 27], device='cuda:0'), tensor([1, 4, 1], device='cuda:0'), tensor([ 5,  1, 13], device='cuda:0'), tensor([ 0, 17,  1], device='cuda:0'), tensor([20, 18, 25], device='cuda:0'), tensor([ 1, 26, 24], device='cuda:0'), tensor([ 3,  1, 30], device='cuda:0'), tensor([ 1, 13, 30], device='cuda:0'), tensor([ 1,  1, 30], device='cuda:0'), tensor([ 1, 25, 29], device='cuda:0'), tensor([ 1, 24,  1], device='cuda:0'), tensor([ 1, 25,  5], device='cuda:0'), tensor([ 1, 30,  1], device='cuda:0'), tensor([ 1, 30,  5], device='cuda:0'), tensor([ 1, 32,  1], device='cuda:0'), tensor([ 1,  1, 10], device='cuda:0'), tensor([ 1, 10,  1], device='cuda:0'), tensor([1, 1, 4], device='cuda:0'), tensor([ 1, 17,  1], device='cuda:0'), tensor([ 1, 18,  7], device='cuda:0'), tensor([ 1, 26, 19], device='cuda:0'), tensor([ 1,  1, 26], device='cuda:0'), tensor([ 1, 12, 33], device='cuda:0'), tensor([ 1,  1, 21], device='cuda:0'), tensor([ 1, 26, 27], device='cuda:0'), tensor([ 1, 24, 25], device='cuda:0'), tensor([ 1, 28, 20], device='cuda:0'), tensor([ 1, 32,  1], device='cuda:0'), tensor([ 1, 33,  4], device='cuda:0'), tensor([ 1, 33,  1], device='cuda:0'), tensor([1, 1, 4], device='cuda:0'), tensor([1, 5, 1], device='cuda:0'), tensor([1, 1, 6], device='cuda:0'), tensor([ 1,  9, 19], device='cuda:0'), tensor([ 1,  1, 30], device='cuda:0'), tensor([ 1, 17, 21], device='cuda:0'), tensor([ 1, 18, 34], device='cuda:0'), tensor([ 1, 25, 20], device='cuda:0'), tensor([1, 1, 1], device='cuda:0'), tensor([ 1, 13,  4], device='cuda:0'), tensor([1, 1, 1], device='cuda:0'), tensor([ 1, 25, 17], device='cuda:0'), tensor([ 1, 24, 18], device='cuda:0'), tensor([ 1, 33, 25], device='cuda:0'), tensor([ 1, 30,  1], device='cuda:0'), tensor([ 1, 26, 13], device='cuda:0'), tensor([ 1, 27,  1], device='cuda:0'), tensor([ 1,  1, 23], device='cuda:0'), tensor([ 1,  5, 25], device='cuda:0'), tensor([ 1,  0, 24], device='cuda:0'), tensor([ 1, 21, 31], device='cuda:0'), tensor([ 1,  1, 31], device='cuda:0'), tensor([1, 0, 1], device='cuda:0'), tensor([1, 4, 5], device='cuda:0'), tensor([1, 1, 1], device='cuda:0'), tensor([ 1,  4, 10], device='cuda:0'), tensor([1, 1, 1], device='cuda:0'), tensor([ 1,  7, 17], device='cuda:0'), tensor([ 1, 19, 18], device='cuda:0'), tensor([ 1, 30, 25], device='cuda:0'), tensor([ 1, 21,  1], device='cuda:0'), tensor([ 1, 34, 13], device='cuda:0'), tensor([ 1, 20,  1], device='cuda:0'), tensor([ 1,  1, 25], device='cuda:0'), tensor([ 1,  4, 24], device='cuda:0'), tensor([ 1,  1, 33], device='cuda:0'), tensor([ 1,  7, 30], device='cuda:0'), tensor([ 1,  1, 27], device='cuda:0'), tensor([ 1,  4, 30], device='cuda:0'), tensor([1, 1, 1], device='cuda:0'), tensor([ 1, 17,  5], device='cuda:0'), tensor([ 1, 18,  1], device='cuda:0'), tensor([ 1, 25,  5], device='cuda:0'), tensor([1, 1, 1], device='cuda:0'), tensor([ 1, 13,  9], device='cuda:0'), tensor([1, 1, 1], device='cuda:0'), tensor([ 1, 23,  7], device='cuda:0'), tensor([ 1, 25, 19], device='cuda:0'), tensor([ 1, 24, 26], device='cuda:0'), tensor([ 1, 31, 32], device='cuda:0'), tensor([ 1, 29, 21], device='cuda:0'), tensor([ 1, 33, 22], device='cuda:0'), tensor([ 1, 31, 20], device='cuda:0'), tensor([1, 1, 1], device='cuda:0'), tensor([1, 5, 4], device='cuda:0'), tensor([1, 1, 1], device='cuda:0'), tensor([1, 5, 4], device='cuda:0'), tensor([1, 1, 1], device='cuda:0'), tensor([1, 9, 6], device='cuda:0'), tensor([1, 1, 1], device='cuda:0'), tensor([1, 4, 4], device='cuda:0'), tensor([1, 1, 1], device='cuda:0'), tensor([ 1,  6, 17], device='cuda:0'), tensor([ 1, 19, 18], device='cuda:0'), tensor([ 1, 26, 25], device='cuda:0'), tensor([ 1, 21,  1], device='cuda:0'), tensor([ 1, 26, 13], device='cuda:0'), tensor([ 1, 27,  1], device='cuda:0'), tensor([ 1, 20, 23], device='cuda:0'), tensor([ 1,  1, 25], device='cuda:0'), tensor([ 1,  4, 24], device='cuda:0'), tensor([ 1,  1, 34], device='cuda:0'), tensor([ 1, 17, 30], device='cuda:0'), tensor([ 1, 18, 33], device='cuda:0'), tensor([ 1, 26, 33], device='cuda:0'), tensor([1, 1, 1], device='cuda:0'), tensor([ 1, 12,  5], device='cuda:0'), tensor([1, 1, 1], device='cuda:0'), tensor([ 1, 25, 10], device='cuda:0'), tensor([ 1, 24,  1], device='cuda:0'), tensor([ 1, 31, 17], device='cuda:0'), tensor([ 1, 34, 18], device='cuda:0'), tensor([ 1, 29, 26], device='cuda:0'), tensor([ 1, 31,  1], device='cuda:0'), tensor([ 1,  1, 12], device='cuda:0'), tensor([1, 5, 1], device='cuda:0'), tensor([ 1,  1, 23], device='cuda:0'), tensor([ 1,  8, 25], device='cuda:0'), tensor([ 1, 19, 24], device='cuda:0'), tensor([ 1, 26, 32], device='cuda:0'), tensor([ 1, 32, 30], device='cuda:0'), tensor([ 1, 21, 33], device='cuda:0'), tensor([ 1, 27, 31], device='cuda:0')]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18ae932e75c94c91b085cc6f3517374c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([ 2, 26,  1], device='cuda:0'), tensor([ 1, 20,  5], device='cuda:0'), tensor([19,  1,  1], device='cuda:0'), tensor([ 0, 17,  5], device='cuda:0'), tensor([ 4, 18,  1], device='cuda:0'), tensor([ 1, 27,  5], device='cuda:0'), tensor([4, 1, 1], device='cuda:0'), tensor([ 1, 13,  5], device='cuda:0'), tensor([17,  1,  0], device='cuda:0'), tensor([18, 25, 20], device='cuda:0'), tensor([26, 24,  1], device='cuda:0'), tensor([ 1, 30,  3], device='cuda:0'), tensor([13, 30,  1], device='cuda:0'), tensor([ 1, 30,  1], device='cuda:0'), tensor([25, 29,  1], device='cuda:0'), tensor([24,  1,  1], device='cuda:0'), tensor([25,  5,  1], device='cuda:0'), tensor([30,  1,  1], device='cuda:0'), tensor([30,  5,  1], device='cuda:0'), tensor([32,  1,  1], device='cuda:0'), tensor([ 1, 10,  1], device='cuda:0'), tensor([10,  1,  1], device='cuda:0'), tensor([1, 4, 1], device='cuda:0'), tensor([17,  1,  1], device='cuda:0'), tensor([18,  7,  1], device='cuda:0'), tensor([26, 19,  1], device='cuda:0'), tensor([ 1, 26,  1], device='cuda:0'), tensor([12, 33,  1], device='cuda:0'), tensor([ 1, 21,  1], device='cuda:0'), tensor([26, 27,  1], device='cuda:0'), tensor([24, 25,  1], device='cuda:0'), tensor([28, 20,  1], device='cuda:0'), tensor([32,  1,  1], device='cuda:0'), tensor([33,  4,  1], device='cuda:0'), tensor([33,  1,  1], device='cuda:0'), tensor([1, 4, 1], device='cuda:0'), tensor([5, 1, 1], device='cuda:0'), tensor([1, 6, 1], device='cuda:0'), tensor([ 9, 19,  1], device='cuda:0'), tensor([ 1, 30,  1], device='cuda:0'), tensor([17, 21,  1], device='cuda:0'), tensor([18, 34,  1], device='cuda:0'), tensor([25, 20,  1], device='cuda:0'), tensor([1, 1, 1], device='cuda:0'), tensor([13,  4,  1], device='cuda:0'), tensor([1, 1, 1], device='cuda:0'), tensor([25, 17,  1], device='cuda:0'), tensor([24, 18,  1], device='cuda:0'), tensor([33, 25,  1], device='cuda:0'), tensor([30,  1,  1], device='cuda:0'), tensor([26, 13,  1], device='cuda:0'), tensor([27,  1,  1], device='cuda:0'), tensor([ 1, 23,  1], device='cuda:0'), tensor([ 5, 25,  1], device='cuda:0'), tensor([ 0, 24,  1], device='cuda:0'), tensor([21, 31,  1], device='cuda:0'), tensor([ 1, 31,  1], device='cuda:0'), tensor([0, 1, 1], device='cuda:0'), tensor([4, 5, 1], device='cuda:0'), tensor([1, 1, 1], device='cuda:0'), tensor([ 4, 10,  1], device='cuda:0'), tensor([1, 1, 1], device='cuda:0'), tensor([ 7, 17,  1], device='cuda:0'), tensor([19, 18,  1], device='cuda:0'), tensor([30, 25,  1], device='cuda:0'), tensor([21,  1,  1], device='cuda:0'), tensor([34, 13,  1], device='cuda:0'), tensor([20,  1,  1], device='cuda:0'), tensor([ 1, 25,  1], device='cuda:0'), tensor([ 4, 24,  1], device='cuda:0'), tensor([ 1, 33,  1], device='cuda:0'), tensor([ 7, 30,  1], device='cuda:0'), tensor([ 1, 27,  1], device='cuda:0'), tensor([ 4, 30,  1], device='cuda:0'), tensor([1, 1, 1], device='cuda:0'), tensor([17,  5,  1], device='cuda:0'), tensor([18,  1,  1], device='cuda:0'), tensor([25,  5,  1], device='cuda:0'), tensor([1, 1, 1], device='cuda:0'), tensor([13,  9,  1], device='cuda:0'), tensor([1, 1, 1], device='cuda:0'), tensor([23,  7,  1], device='cuda:0'), tensor([25, 19,  1], device='cuda:0'), tensor([24, 26,  1], device='cuda:0'), tensor([31, 32,  1], device='cuda:0'), tensor([29, 21,  1], device='cuda:0'), tensor([33, 22,  1], device='cuda:0'), tensor([31, 20,  1], device='cuda:0'), tensor([1, 1, 1], device='cuda:0'), tensor([5, 4, 1], device='cuda:0'), tensor([1, 1, 1], device='cuda:0'), tensor([5, 4, 1], device='cuda:0'), tensor([1, 1, 1], device='cuda:0'), tensor([9, 6, 1], device='cuda:0'), tensor([1, 1, 1], device='cuda:0'), tensor([4, 4, 1], device='cuda:0'), tensor([1, 1, 1], device='cuda:0'), tensor([ 6, 17,  1], device='cuda:0'), tensor([19, 18,  1], device='cuda:0'), tensor([26, 25,  1], device='cuda:0'), tensor([21,  1,  1], device='cuda:0'), tensor([26, 13,  1], device='cuda:0'), tensor([27,  1,  1], device='cuda:0'), tensor([20, 23,  1], device='cuda:0'), tensor([ 1, 25,  1], device='cuda:0'), tensor([ 4, 24,  1], device='cuda:0'), tensor([ 1, 34,  1], device='cuda:0'), tensor([17, 30,  1], device='cuda:0'), tensor([18, 33,  1], device='cuda:0'), tensor([26, 33,  1], device='cuda:0'), tensor([1, 1, 1], device='cuda:0'), tensor([12,  5,  1], device='cuda:0'), tensor([1, 1, 1], device='cuda:0'), tensor([25, 10,  1], device='cuda:0'), tensor([24,  1,  1], device='cuda:0'), tensor([31, 17,  1], device='cuda:0'), tensor([34, 18,  1], device='cuda:0'), tensor([29, 26,  1], device='cuda:0'), tensor([31,  1,  1], device='cuda:0'), tensor([ 1, 12,  1], device='cuda:0'), tensor([5, 1, 1], device='cuda:0'), tensor([ 1, 23,  1], device='cuda:0'), tensor([ 8, 25,  1], device='cuda:0'), tensor([19, 24,  1], device='cuda:0'), tensor([26, 32,  1], device='cuda:0'), tensor([32, 30,  1], device='cuda:0'), tensor([21, 33,  1], device='cuda:0'), tensor([27, 31,  1], device='cuda:0')]\n"
     ]
    }
   ],
   "source": [
    "# Training Loop\n",
    "for epoch in range(args['num_train_epochs']):\n",
    "    model.train()\n",
    "    progress_bar = tqdm(train_dataloader, desc=f\"Epoch {epoch}\")\n",
    "    total_loss = 0\n",
    "    for step, batch in enumerate(progress_bar):\n",
    "        with accelerator.accumulate(model):\n",
    "            print(batch)\n",
    "            # outputs = model(**batch)\n",
    "            # loss = outputs.loss\n",
    "            # total_loss += loss.item()\n",
    "            # accelerator.backward(loss)\n",
    "            # optimizer.step()\n",
    "            # lr_scheduler.step()\n",
    "            # optimizer.zero_grad()\n",
    "\n",
    "        progress_bar.set_postfix(loss=total_loss / (step + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1d6783-7407-46a2-9d62-19c1f05f7b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    eval_loss = 0\n",
    "    for step, batch in enumerate(eval_dataloader):\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**batch)\n",
    "            eval_loss += outputs.loss.item()\n",
    "\n",
    "    eval_loss /= len(eval_dataloader)\n",
    "    perplexity = math.exp(eval_loss) if eval_loss < 100 else float('inf')\n",
    "    print(f\"Epoch {epoch} evaluation loss: {eval_loss}, perplexity: {perplexity}\")\n",
    "\n",
    "    # Save checkpoint\n",
    "    if args['checkpointing_steps'] == 'epoch' and (epoch + 1) % 1 == 0:\n",
    "        output_dir = os.path.join(args['output_dir'], f\"epoch_{epoch}\")\n",
    "        model.save_pretrained(output_dir)\n",
    "        tokenizer.save_pretrained(output_dir)\n",
    "\n",
    "# Final model saving\n",
    "model.save_pretrained(args['output_dir'])\n",
    "tokenizer.save_pretrained(args['output_dir'])\n",
    "\n",
    "print(\"Training completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3cb37b-3c71-4cbe-bf62-c11094aeb396",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
